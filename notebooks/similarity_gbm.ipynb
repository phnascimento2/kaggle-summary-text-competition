{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91209dc4-8a78-4c84-8890-00fa04ba4ff4",
   "metadata": {},
   "source": [
    "# Baseline using text similarity and XGB\n",
    "\n",
    "Using sentence transformer model to compute similarity between summary and texts. Then train XGB to predict from similarity scores and texts sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c096904-abba-4687-8c82-1c826ac8c76d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8e6e0c-0922-4daf-884d-28e5559ea5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67baf417-493a-4303-9e36-e3dd5ae59a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datapath = Path(\"../data/\")\n",
    "\n",
    "train_pro = pd.read_csv(datapath / \"prompts_train.csv\")\n",
    "train_sum = pd.read_csv(datapath / \"summaries_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ee1c36-7099-4918-940b-cb71e2f4ead0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_emb = {pid: emb for pid,emb in zip(train_pro.prompt_id.values, model.encode(train_pro.prompt_text.values))}\n",
    "question_emb = {pid: emb for pid,emb in zip(train_pro.prompt_id.values, model.encode(train_pro.prompt_question.values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ce7dd-addf-4b91-a534-b4a920c889ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum_emb = {sid: emb for sid,emb in zip(train_sum.student_id.values, model.encode(train_sum.text.values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070be914-5077-4ec5-9949-2197438bae9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cossim = {}\n",
    "for k in text_emb.keys():\n",
    "    cossim[k] = cosine_similarity(text_emb[k].reshape(1,-1), question_emb[k].reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db428e-c81f-417c-b587-7b2328197d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cs_text = []\n",
    "cs_question = []\n",
    "for sid, pid in train_sum[[\"student_id\",\"prompt_id\"]].values:\n",
    "    cs_text.append(\n",
    "        cosine_similarity(text_emb[pid].reshape(1,-1), sum_emb[sid].reshape(1,-1))[0][0]\n",
    "    )\n",
    "    cs_question.append(\n",
    "        cosine_similarity(question_emb[pid].reshape(1,-1), sum_emb[sid].reshape(1,-1))[0][0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160d07f-101e-4a26-a2f5-390922319b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sum[\"cs_text\"] = cs_text\n",
    "train_sum[\"cs_question\"] = cs_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501322d-0923-4167-a491-c94f9b2d1c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sum.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2086ae-8d6b-4925-93e4-7c935a7cf315",
   "metadata": {
    "tags": []
   },
   "source": [
    "Features relacionadas com o tamanho do texto e do sum√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3584fb-a057-4c67-8dc9-a4aa174ad251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pro[\"ptext_words\"] = train_pro.prompt_text.apply(lambda x: len(x.split()))\n",
    "train_pro[\"ptext_chars\"] = train_pro.prompt_text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74138ca-7692-4245-8d92-106a4c0e5599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sum[\"stext_words\"] = train_sum.text.apply(lambda x: len(x.split()))\n",
    "train_sum[\"stext_chars\"] = train_sum.text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e2d36-08be-4c4b-881f-289f89b448d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sum = train_sum.merge(train_pro[[\"prompt_id\", \"ptext_words\", \"ptext_chars\"]], \n",
    "                            on=\"prompt_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe3a2a-805e-4b6e-992a-663fcfb0bf48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make fold numbers, one fold for each prompt_id\n",
    "foldmapper = {v:i for i,v in enumerate(train_sum.prompt_id.unique())}\n",
    "train_sum[\"fold\"] = train_sum.prompt_id.map(foldmapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e426e2-df01-4efd-b9dd-9416f022f291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_sum.to_parquet(\"tmp_train.parquet\", index=False)\n",
    "train_sum = pd.read_parquet(\"tmp_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0705d9-95ac-408d-a8f9-00765bf1f65a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_sum\n",
    "feat = [\"cs_text\", \"cs_question\", \"stext_words\", \"stext_chars\", \"ptext_words\", \"ptext_chars\"]\n",
    "targets = [\"content\", \"wording\"]\n",
    "model_dict = {}\n",
    "\n",
    "for target in targets:\n",
    "    models = []\n",
    "    \n",
    "    for fold in range(4):\n",
    "\n",
    "        Xtrain = train[train[\"fold\"] != fold][feat]\n",
    "        ytrain = train[train[\"fold\"] != fold][target]\n",
    "\n",
    "        Xvalid = train[train[\"fold\"] == fold][feat]\n",
    "        yvalid = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        dtrain = lgb.Dataset(Xtrain, label=ytrain)\n",
    "        dval = lgb.Dataset(Xvalid, label=yvalid)\n",
    "\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'random_state': 42,\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'learning_rate': 0.05,\n",
    "            'max_depth': 3,\n",
    "            'lambda_l1': 0,\n",
    "            'lambda_l2': 0.01\n",
    "        }\n",
    "\n",
    "        evaluation_results = {}\n",
    "        model = lgb.train(params,\n",
    "                          num_boost_round=1000,\n",
    "                          valid_names=['train', 'valid'],\n",
    "                          train_set=dtrain,\n",
    "                          valid_sets=dval,\n",
    "                          callbacks=[\n",
    "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
    "                              lgb.log_evaluation(50)\n",
    "                              lgb.callback.record_evaluation(evaluation_results)\n",
    "                            ],\n",
    "                          )\n",
    "        models.append(model)\n",
    "    \n",
    "    model_dict[target] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1553e30-5297-4f33-941e-ccdf3388284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = []\n",
    "\n",
    "for target in targets:\n",
    "    models = model_dict[target]\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    for fold, model in enumerate(models):\n",
    "        Xeval = train[train[\"fold\"] == fold][feat]\n",
    "        yeval = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        pred = model.predict(Xeval)\n",
    "\n",
    "        trues.extend(yeval)\n",
    "        preds.extend(pred)\n",
    "        \n",
    "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "    print(f\"{target}_rmse : {rmse}\")\n",
    "    rmses = rmses + [rmse]\n",
    "\n",
    "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3fdfc2a-1b3f-4adb-93fa-9a934caa3894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c55ef4-8112-4746-9122-e95dddb74f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
